{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Sarcasm Detection on YouTube Comments\n",
        "\n",
        "### 1. Problem Statement:\n",
        "\n",
        "Detecting sarcasm in YouTube comments is essential for accurate sentiment analysis. Sarcasm often expresses the opposite of literal meaning, making it challenging for traditional NLP methods to interpret correctly.\n",
        "\n",
        "### 2. Solution Description:\n",
        "\n",
        "Develop a machine learning model using TF-IDF vectorization and a Feedforward Neural Network (FNN) to classify YouTube comments as sarcastic or non-sarcastic.\n",
        "\n",
        "### 3. Dataset Description:\n",
        "\n",
        "The dataset contains approximately 20,000 preprocessed YouTube comments labeled as sarcastic (1) or non-sarcastic (0). It is split into training, validation, and test sets for model development and evaluation.\n",
        "\n",
        "### 4. Data Visualization:\n",
        "\n",
        "#### a. Train, Test, and Validation Set Sizes\n",
        "\n",
        "- Training Set: 15,536 comments\n",
        "- Validation Set: 3,884 comments\n",
        "\n",
        "![Traing ,Test and Valiation sets](https://drive.google.com/uc?export=view&id=14Vb1JppPRxpnlZF35-COJZ4cmraFfxgE)\n",
        "\n",
        "\n",
        "#### b. Label-wise Distribution in Training Data:\n",
        "\n",
        "- Sarcastic (1): 7,768 comments\n",
        "- Non-sarcastic (0): 7,768 comments\n",
        "\n",
        "![Label-wise distribution](https://drive.google.com/uc?export=view&id=14T9hslcR_Nf_-Pv7c3kkna-P47jgfZVB)\n",
        "\n",
        "\n",
        "### Model Architecture:\n",
        "\n",
        "**Feedforward Neural Network (FNN)**\n",
        "\n",
        "A Feedforward Neural Network (FNN) consists of multiple layers where information flows in one direction, from input nodes through intermediate (hidden) nodes to output nodes. Each layer is fully connected to the next layer without feedback loops.\n",
        "\n",
        "- **Input Layer**:\n",
        "  - Input shape: Determined by the number of features in the input data.\n",
        "\n",
        "- **Hidden Layers**:\n",
        "  - Dense layers with varying numbers of units and ReLU activation function.\n",
        "  - Dropout layers with a dropout rate of 0.3 are added after certain dense layers to prevent overfitting.\n",
        "\n",
        "- **Output Layer**:\n",
        "  - One output unit with a sigmoid activation function for binary classification.\n",
        "\n",
        "\n",
        "Total params: 6,641,409\n",
        "Trainable params: 6,641,409\n",
        "Non-trainable params: 0\n",
        "\n",
        "\n",
        "### Training Configuration:\n",
        "\n",
        "- **Optimizer**: Adam optimizer.\n",
        "- **Loss Function**: Binary cross-entropy.\n",
        "- **Metrics**: Accuracy.\n",
        "- **Callbacks**:\n",
        "  - **Early Stopping**: Monitors validation loss and stops training if no improvement after 10 epochs, restoring the best weights.\n",
        "  - **Reduce Learning Rate on Plateau**: Reduces learning rate by a factor of 0.2 if validation loss does not improve for 5 epochs.\n",
        "\n",
        "### Model Training:\n",
        "\n",
        "The model is trained for up to 20 epochs with a batch size of 128. Early stopping and learning rate reduction callbacks are used to enhance training efficiency and prevent overfitting. Adjustments to these parameters may be necessary based on specific dataset characteristics and performance metrics observed during training.\n",
        "\n",
        "\n",
        "\n",
        "**Classification Report:**\n",
        "\n",
        "![Classification Report](https://drive.google.com/uc?export=view&id=14kkO2r3Qtkqlus5fvLLOmHT2GQfWSMLQ)\n",
        "\n",
        "\n",
        "![Confusion Matrix](https://drive.google.com/uc?export=view&id=14_fmPjnirYTSYMsp1AowYXyu1B69siUE)\n"
      ],
      "metadata": {
        "id": "J4VqaK43Y-Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Importing required libraries"
      ],
      "metadata": {
        "id": "7qqXjStxZmU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p2jG3TF-Xy7",
        "outputId": "aa010aff-6117-47dc-f145-1ef143a87bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#importing required Libraries\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the Pre-trained Model and TF-IDF Vectorizer\n"
      ],
      "metadata": {
        "id": "a4EEHuqvZCrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from Google Drive\n",
        "model_path = '/content/drive/MyDrive/path_to_my_model/model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "#Loading TF-IDF\n",
        "with open('/content/drive/MyDrive/sarcasm_detection/tfidf222_preprocessed_data.pkl', 'rb') as file:\n",
        "    tfidf_vectorizer, X_train, X_test, y_train, y_test = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "U-D40mNr-zoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Predict Sarcasm in New Text Inputs\n"
      ],
      "metadata": {
        "id": "oeZJcOREZKsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict sarcasm\n",
        "def predict_sarcasm(model, vectorizer, text):\n",
        "    text_vector = vectorizer.transform([text]).toarray()  # Convert to dense array\n",
        "    prediction = (model.predict(text_vector) > 0.5).astype(\"int32\")\n",
        "    return \"Sarcasm\" if prediction == 1 else \"Not Sarcasm\"\n",
        "\n",
        "# Input texts for prediction\n",
        "new_texts = [\n",
        "\"I just love getting stuck in traffic.\",  # Sarcastic example\n",
        "\"truth toofunny willandgrace handersen 79.\",#Sarcastic\n",
        "\"editing b bad il justify later life chat emoticon.\",#Sarcastic\n",
        "\"truth deadgenius listen satire humor LOL.\",#Sarcastic\n",
        "\"irony YouTube popular vlogger tells YouTube joke.\",#Sarcastic\n",
        "\"took 2 year put gladly spend next 2 colombia learned so much.\",#Not sarcastic\n",
        "\"spent 10 min playing dog looked like happy human.\",#Not Sarcastic\n",
        "\"enjoy reading books during my free time.\",#Not Sarcastic\n",
        "\"great video glad stumbled upon channel.\",#Not Sarcastic\n",
        "\"love channel keep good work.\"#Not Sarcastic\n",
        "]\n",
        "\n",
        "\n",
        "# Print predictions\n",
        "for text in new_texts:\n",
        "    print(f\"Text: {text} - Prediction: {predict_sarcasm(model, tfidf_vectorizer, text)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx4b_1hX_gGA",
        "outputId": "a4d832f6-4362-4aa1-83e0-407c462171d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Text: I just love getting stuck in traffic. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Text: truth toofunny willandgrace handersen 79. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Text: editing b bad il justify later life chat emoticon. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Text: truth deadgenius listen satire humor LOL. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Text: irony YouTube popular vlogger tells YouTube joke. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Text: took 2 year put gladly spend next 2 colombia learned so much. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Text: spent 10 min playing dog looked like happy human. - Prediction: Not Sarcasm\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Text: enjoy reading books during my free time. - Prediction: Not Sarcasm\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Text: great video glad stumbled upon channel. - Prediction: Sarcasm\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Text: love channel keep good work. - Prediction: Not Sarcasm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upzs14EFAzce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}